---
title: "Playback & Embedding"
description: "Share your stream with viewers using the FrameWorks player or standard protocols."
sidebar:
  order: 3
---

import { Aside } from '@astrojs/starlight/components';

Now that you're broadcasting, let's get your stream to your audience. FrameWorks provides versatile playback options, from a drop-in React component to raw protocol support for HLS, DASH, and WebRTC.

<Aside type="note" title="Self-hosted delivery">
Self-hosted operators serve streams from their own edge nodes. The same protocols and player work—just point to your Foghorn load balancer instead.
</Aside>

## Where to Find Your Playback URLs

You can find your **Playback ID** in the FrameWorks dashboard under the **Playback Info** card of your stream. This ID is public-safe and used to construct all viewer URLs.

**Primary Protocols:**
- **HLS (HTTP Live Streaming):** The industry standard for broad compatibility (browsers, mobile apps, smart TVs).
- **HLS (CMAF):** Lower latency HLS variant using Common Media Application Format.
- **DASH (MPEG-DASH):** Adaptive bitrate protocol often used on Android and set-top boxes.
- **WebRTC (WHEP):** Ultra-low latency streaming (~0.5s) for real-time interactivity.
- **SRT:** Secure Reliable Transport for low-latency contribution and delivery.
- **MP4/WebM:** Progressive download formats for wide compatibility.

**Additional Protocols:** RTSP, RTMP, MPEG-TS, FLV, MKV, AAC (audio-only), Smooth Streaming, HDS, and more. See [Supported Protocols](#supported-protocols) for the full list.

<Aside type="note" title="Powered by MistServer">
FrameWorks uses MistServer for transcoding and delivery, which supports nearly every video codec and container format with on-the-fly muxing. For detailed protocol documentation, see [docs.mistserver.org](https://docs.mistserver.org/).
</Aside>

The URLs follow a unified pattern through Foghorn's `/play/` path:
```
HLS:    %PLAY_URL%/play/{content-id}/hls/index.m3u8
DASH:   %PLAY_URL%/play/{content-id}/cmaf/index.mpd
WebRTC: %PLAY_URL%/play/{content-id}/webrtc
MP4:    %PLAY_URL%/play/{content-id}.mp4
```

**Common URL paths:**
| Protocol | Path |
|----------|------|
| HLS (TS) | `/play/{id}/hls/index.m3u8` |
| HLS (CMAF) | `/play/{id}/cmaf/index.m3u8` |
| DASH | `/play/{id}/cmaf/index.mpd` |
| WebRTC (WHEP) | `/play/{id}/webrtc` |
| MP4 | `/play/{id}.mp4` |
| WebM | `/play/{id}.webm` |

Where `{id}` is:
- **Live streams:** Your `playbackId` (view key)
- **Clips:** The `clipHash` (32-character identifier)
- **DVR recordings:** The `dvrHash` (32-character identifier)

Your playback ID is different from your stream key (which is secret and used for ingest only).

## The FrameWorks Player

The FrameWorks Player is a React component that wraps multiple open-source playback engines (hls.js, dash.js, Video.js) and implements its own native WebSocket-based playback stack. It provides tight integration with both MistServer and the FrameWorks platform.

**Key features:**

- **Multi-engine architecture** — Wraps hls.js, dash.js, Video.js, and the native MistPlayer, selecting the best engine for each browser and protocol combination
- **Native WebSocket player** — Custom MSE-based player (`MewsWsPlayer`) for ultra-low-latency WebSocket streams directly from MistServer
- **Intelligent protocol selection** — Ported from MistServer's MistMetaPlayer algorithm, scoring player/source combinations by codec support, browser compatibility, and source priority
- **Adaptive bitrate (ABR)** — Built-in ABR controller with resize-aware and bitrate-aware modes that match quality to viewport size and network conditions
- **Gateway integration** — Resolves optimal edge nodes via the FrameWorks Gateway GraphQL API, no manual URL construction needed
- **Telemetry reporting** — Batched playback metrics (stalls, quality score, dropped frames) sent to your analytics endpoint with `sendBeacon()` for reliable page-unload reporting
- **Lazy-loaded transports** — Heavy player bundles are loaded on-demand, keeping initial bundle size small

### Controls & Shortcuts

The player supports keyboard and gesture shortcuts once the player is focused (click/tap once to focus).

**Keyboard**
| Shortcut | Action | Notes |
|---|---|---|
| Space | Play/Pause | Hold = 2× speed (when seekable) |
| K | Play/Pause | YouTube-style |
| J / ← | Skip back 10s | Disabled on live-only |
| L / → | Skip forward 10s | Disabled on live-only |
| ↑ / ↓ | Volume ±10% | — |
| M | Mute/Unmute | — |
| F | Fullscreen toggle | — |
| C | Captions toggle | — |
| 0–9 | Seek to 0–90% | Disabled on live-only |
| , / . | Prev/Next frame (paused) | WebCodecs = true step; others = buffered-only |

**Mouse / Touch**
| Gesture | Action | Notes |
|---|---|---|
| Double‑click | Fullscreen toggle | Desktop |
| Double‑tap (left/right) | Skip ±10s | Touch only, disabled on live-only |
| Click/Tap & Hold | 2× speed | Disabled on live-only |

**Constraints**
- **Live-only** streams disable seeking/skip/2× hold and frame-step.
- **Live with DVR buffer** enables the same shortcuts as VOD.
- Frame stepping only moves within **already buffered** ranges (no network seek). WebCodecs supports true frame stepping when paused.

### Installation

```bash
# React
npm install @livepeer-frameworks/player-react

# Svelte 5
npm install @livepeer-frameworks/player-svelte

# Vanilla JS / Other frameworks
npm install @livepeer-frameworks/player-core
```

```tsx
// Import CSS from your wrapper package
import '@livepeer-frameworks/player-react/player.css';  // React
import '@livepeer-frameworks/player-svelte/player.css'; // Svelte
import '@livepeer-frameworks/player-core/player.css';   // Vanilla
```

### Using the Player Component

The simplest way to embed a stream is by passing your Playback ID. The player will automatically resolve the best available edge node.

```tsx
import { Player } from '@livepeer-frameworks/player-react';

function LiveStream() {
  return (
    <Player
      contentType="live"
      contentId="<YOUR_PLAYBACK_ID>"  // Your stream's Playback ID
      options={{
        gatewayUrl: '%API_URL%',
        autoplay: true,
        muted: true,  // Required for autoplay in browsers
      }}
    />
  );
}
```

The player queries the Gateway to resolve the best edge node for your viewer's location.

### Direct Endpoint Override (Advanced)

If you already have resolved endpoints (e.g. from your own backend) or want to force a specific MistServer node, you can bypass the Gateway by passing `endpoints` directly:

```tsx
<Player
  contentType="live"
  contentId="<YOUR_PLAYBACK_ID>"
  endpoints={{
    // Direct MistServer base URL
    http: "%EDGE_URL%",
    ws: "%EDGE_URL%"
  }}
  options={{
    autoplay: true,
    muted: true,
  }}
/>
```

When `endpoints` is provided, the `gatewayUrl` is ignored and the player connects directly to the specified node.

### For DVR and Clips

Same component, different content type. The player automatically resolves the correct edge node for playback:

```tsx
// DVR recording - use the dvrHash from the recording
<Player contentType="dvr" contentId="a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6" />

// Clip - use the clipHash from the clip
<Player contentType="clip" contentId="f8a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6" />
```

You can also access DVR recordings and clips directly via URL:

```bash
# DVR recording
https://play.example.com/play/{dvrHash}/hls/index.m3u8
https://play.example.com/play/{dvrHash}.mp4

# Clip
https://play.example.com/play/{clipHash}/hls/index.m3u8
https://play.example.com/play/{clipHash}.mp4
```

Find these identifiers in the FrameWorks dashboard under **Recordings** and **Clips**. Each recording and clip shows its hash and provides copy buttons for all protocol URLs.

### With Thumbnail/Poster

```tsx
<Player
  contentType="live"
  contentId="my-stream"
  thumbnailUrl="https://your-cdn.com/poster.jpg"
  options={{
    gatewayUrl: '%API_URL%',
    autoplay: false,  // Wait for user interaction
  }}
/>
```

### State Callbacks

Track player lifecycle for UI feedback:

```tsx
<Player
  contentType="live"
  contentId="my-stream"
  options={{ gatewayUrl: '%API_URL%' }}
  onStateChange={(state, context) => {
    // States: booting, gateway_loading, gateway_ready, gateway_error, no_endpoint,
    //         selecting_player, connecting, buffering, playing, paused, ended, error, destroyed
    console.log('Player state:', state, context);
  }}
/>
```

### Vanilla JS / Non-React Usage

For Svelte, Vue, Angular, or plain JavaScript, use the `FrameWorksPlayer` class instead of the React component:

```ts
import { FrameWorksPlayer } from '@livepeer-frameworks/player-core';
import '@livepeer-frameworks/player-core/player.css';

const player = new FrameWorksPlayer('#player-container', {
  contentId: '<YOUR_PLAYBACK_ID>',
  contentType: 'live',
  gatewayUrl: '%API_URL%',
  autoplay: true,
  muted: true,
  onStateChange: (state) => console.log('State:', state),
  onReady: (videoElement) => console.log('Ready!'),
});

// Control playback
player.play();
player.pause();
player.seek(30);        // Seek to 30 seconds
player.setVolume(0.5);  // 50% volume
player.jumpToLive();    // Jump to live edge

// Cleanup when done
player.destroy();
```

### Direct Endpoint Override (Vanilla)

```ts
const player = new FrameWorksPlayer('#player-container', {
  contentId: '<YOUR_PLAYBACK_ID>',
  contentType: 'live',
  // Skip Gateway resolution and connect directly
  endpoints: {
    http: "%EDGE_URL%",
    ws: "%EDGE_URL%"
  },
  autoplay: true,
});
```

#### Svelte Example

```svelte
<script lang="ts">
  import { onMount, onDestroy } from 'svelte';
  import type { FrameWorksPlayer as FrameWorksPlayerType } from '@livepeer-frameworks/player';

  let container: HTMLDivElement;
  let player: FrameWorksPlayerType | null = null;

  onMount(async () => {
    const { FrameWorksPlayer } = await import('@livepeer-frameworks/player');

    player = new FrameWorksPlayer(container, {
      contentId: 'my-stream',
      contentType: 'live',
      gatewayUrl: '%API_URL%',
      autoplay: true,
      muted: true,
    });
  });

  onDestroy(() => player?.destroy());
</script>

<div bind:this={container} style="width: 100%; height: 500px;"></div>
```

#### Vue Example

```vue
<template>
  <div ref="playerContainer" style="width: 100%; height: 500px;"></div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue';
import type { FrameWorksPlayer as FrameWorksPlayerType } from '@livepeer-frameworks/player-core';

const playerContainer = ref<HTMLDivElement>();
let player: FrameWorksPlayerType | null = null;

onMounted(async () => {
  const { FrameWorksPlayer } = await import('@livepeer-frameworks/player-core');
  await import('@livepeer-frameworks/player-core/player.css');

  if (playerContainer.value) {
    player = new FrameWorksPlayer(playerContainer.value, {
      contentId: 'my-stream',
      contentType: 'live',
      gatewayUrl: '%API_URL%',
      autoplay: true,
      muted: true,
    });
  }
});

onUnmounted(() => player?.destroy());
</script>
```

#### Available Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `contentId` | string | required | Playback ID, DVR hash, or clip hash |
| `contentType` | `'live'` \| `'dvr'` \| `'clip'` | required | Content type |
| `gatewayUrl` | string | - | Gateway GraphQL endpoint |
| `authToken` | string | - | Bearer token for private streams |
| `autoplay` | boolean | `true` | Auto-start playback |
| `muted` | boolean | `true` | Start muted |
| `controls` | boolean | `true` | Show player controls |
| `poster` | string | - | Poster/thumbnail image |
| `onStateChange` | function | - | State change callback |
| `onReady` | function | - | Ready callback (receives video element) |
| `onError` | function | - | Error callback |

## Using Other Players

### Using hls.js Directly

If you need full control over the player:

```html
<script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
<video id="video" controls></video>

<script>
  const video = document.getElementById('video');
  // Replace with your actual edge URL and playback ID
  const hlsUrl = '%EDGE_URL%%HLS_PATH%/{playback-id}/index.m3u8';

  if (Hls.isSupported()) {
    const hls = new Hls();
    hls.loadSource(hlsUrl);
    hls.attachMedia(video);
  } else if (video.canPlayType('application/vnd.apple.mpegurl')) {
    // Safari plays HLS natively
    video.src = hlsUrl;
  }
</script>
```

### Video.js

```html
<link href="https://vjs.zencdn.net/8.0.4/video-js.css" rel="stylesheet" />
<script src="https://vjs.zencdn.net/8.0.4/video.min.js"></script>

<video-js id="my-video" class="video-js" controls data-setup="{}">
  <source
    src="%EDGE_URL%%HLS_PATH%/{playback-id}/index.m3u8"
    type="application/x-mpegURL"
  />
</video-js>
```

## Universal Playback URLs

Instead of constructing URLs manually with edge hostnames, you can use **universal playback URLs** that automatically route viewers to the optimal edge node based on their location.

### Simple Redirect URLs

These URLs work directly with any player (VLC, ffmpeg, native `<video>` tags):

```bash
# HLS - redirects to nearest edge node
%PLAY_URL%/play/{view-key}/hls
%PLAY_URL%/play/{view-key}.m3u8
%PLAY_URL%/play/{view-key}/index.m3u8

# WebRTC (WHEP)
%PLAY_URL%/play/{view-key}/webrtc
%PLAY_URL%/play/{view-key}.webrtc

# DASH
%PLAY_URL%/play/{view-key}/dash
%PLAY_URL%/play/{view-key}.mpd
```

The server returns an **HTTP 307 redirect** to the actual edge node URL, so your player follows the redirect automatically.

**Examples:**
```bash
# Play in VLC
vlc %PLAY_URL%/play/abc123def.m3u8

# Embed in HTML (Safari, iOS)
<video src="%PLAY_URL%/play/abc123def.m3u8" controls></video>

# Record with ffmpeg
ffmpeg -i %PLAY_URL%/play/abc123def/hls -c copy output.mp4
```

### JSON Response (for Custom Players)

If you need all available protocols and fallback nodes, request the full JSON response:

```bash
curl %PLAY_URL%/play/{view-key}
```

Returns:
```json
{
  "primary": {
    "node_id": "edge-7",
    "base_url": "%EDGE_URL%",
    "protocol": "hls",
    "outputs": {
      "HLS": {"url": "%EDGE_URL%/hls/stream-id/index.m3u8"},
      "DASH": {"url": "%EDGE_URL%/cmaf/stream-id/index.mpd"},
      "WebRTC": {"url": "%EDGE_URL%/webrtc/stream-id"}
    }
  },
  "fallbacks": [...]
}
```

### Supported Protocols

#### Primary Protocols

These protocols are shown by default in the dashboard and cover most use cases:

| URL Pattern | Protocol | Description |
|-------------|----------|-------------|
| `/play/{id}/hls/index.m3u8` | HLS (TS) | Best compatibility - browsers, mobile, smart TVs |
| `/play/{id}/cmaf/index.m3u8` | HLS (CMAF) | Lower latency HLS variant |
| `/play/{id}/cmaf/index.mpd` | DASH | MPEG-DASH adaptive streaming |
| `/play/{id}/webrtc` | WebRTC (WHEP) | Ultra-low latency (~0.5s) |
| `/play/{id}.mp4` | MP4 | Progressive download, wide support |
| `/play/{id}.webm` | WebM | Open format (VP8/VP9) |
| `srt://host/?streamid={id}` | SRT | Secure Reliable Transport |

#### Additional Protocols

These protocols are available for specialized use cases:

| URL Pattern | Protocol | Description |
|-------------|----------|-------------|
| `rtsp://host/play/{id}` | RTSP | IP cameras, VLC, ffmpeg |
| `rtmp://host/play/{id}` | RTMP | Legacy Flash players, OBS playback |
| `/play/{id}.ts` | MPEG-TS | Transport stream, DVB compatible |
| `/play/{id}.flv` | FLV | Legacy Flash Video |
| `/play/{id}.mkv` | MKV | Matroska container |
| `/play/{id}.aac` | AAC | Audio-only stream |
| `/play/{id}/cmaf/Manifest` | Smooth Streaming | Microsoft format |
| `/play/{id}/dynamic/manifest.f4m` | HDS | Adobe HTTP Dynamic Streaming |
| `/play/{id}.sdp` | SDP | Session Description Protocol |
| `/play/{id}.h264` | Raw H264 | Elementary video stream |
| `wss://host/play/{id}.mp4` | WebSocket MP4 | MP4 over WebSocket |
| `wss://host/play/webrtc/{id}` | WebSocket WebRTC | WebRTC over WebSocket |
| `dtsc://host/play/{id}` | DTSC | MistServer internal protocol |

<Aside type="tip" title="Protocol Compatibility">
MistServer handles on-the-fly muxing between container formats. Container support depends on source codecs. For detailed codec/container compatibility, see the [MistServer Protocol Documentation](https://docs.mistserver.org/).
</Aside>

### Content Identifiers

The `{id}` in URL patterns refers to different identifiers depending on content type:

| Content Type | Identifier | Example |
|--------------|------------|---------|
| Live Stream | `playbackId` (view key) | `abc123def456` |
| Clip | `clipHash` (32-char hash) | `f8a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6` |
| DVR Recording | `dvrHash` (32-char hash) | `a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6` |

All three content types use the same unified `/play/{id}` path through Foghorn.

:::tip[When to use universal URLs vs. direct URLs]
- **Universal URLs** (`play.example.com/play/...`) - Best for sharing with viewers. Handles geo-routing automatically.
- **Direct URLs** (`edge-X.example.com/hls/...`) - Use when you've already resolved the optimal edge node (e.g., via the FrameWorks Player or GraphQL API).
:::

## Access Control

### Stream Keys vs Playback IDs

Your stream key is for *ingest* only; viewers don't need it. Playback URLs use a separate playback ID that's safe to share publicly.

## Troubleshooting Playback

**Stream Not Found Errors**
- **Is the stream live?** HLS playlists and WHEP endpoints are only active while you are broadcasting.
- **Check the ID:** Ensure you are using the **Playback ID**, not the Stream Key.

**Buffering or Stuttering**
- **Viewer Connection:** The viewer's internet might be insufficient for the source bitrate. HLS attempts to adapt, but a high-bitrate source can still cause issues.
- **Source Bitrate:** Check if your encoder is pushing a bitrate that is too high for your upload speed or your viewers' download speed.

**Autoplay Issues (No Audio)**
- **Browser Policies:** Most modern browsers block autoplay with sound. Ensure your player is set to `muted={true}` for autoplay to work reliably. The FrameWorks Player automatically shows a "Click to Unmute" overlay when playing muted.

**High Latency**
- **Protocol Choice:** HLS naturally has 10-30 seconds of latency. If you require sub-second interaction, switch to using **WebRTC (WHEP)**.
